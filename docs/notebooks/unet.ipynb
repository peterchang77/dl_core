{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "The following lines of code will set up your python/iPython shell with the appropriate requirements and environment variables needed to run this tutorial, as well as download and prepare any necessary data. Of note, all required dependencies and additional tutorials are available at: https://github.com/peterchang77/dl_core. This GitHub repository contains the `dl_core` module and will be used throughout the tutorial. If a copy of this repository is present already, pass the complete path to the repository root directory to the `DL_PATH` variable as described below. \n",
    "\n",
    "The following arguments may be passed to the function:\n",
    "\n",
    "* `DL_PATH`: complete path to the `dl_core` library (GitHub repo); if not present, this path represents location where the GitHub repository will be cloned\n",
    "* `DS_PATH`: complete path to the dataset used in this library; if not present, this path represents location where the data will be downloaded\n",
    "* `DS_NAME`: name of dataset to be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setenv import prepare_environment\n",
    "prepare_environment(\n",
    "    DL_PATH='../../',\n",
    "    DS_PATH='/data/raw/brats',\n",
    "    DS_NAME='brats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import \n",
    "\n",
    "The following modules will be used in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "from dl_core.io import hdf5\n",
    "from dl_core.client import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data you have downloaded above contains preprocessed images and labels in HDF5 format. This data can be loaded directly using the `h5py` Python library, or using a high-level API as part of the `dl_core.io.hdf5` module. Let us load an example image and label pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Find data\n",
    "dirs = sorted(glob.glob('%s/hdfs/*/' % os.environ['DS_PATH']))\n",
    "print('A total of %i patients in dataset' % len(dirs))\n",
    "\n",
    "# --- Load first example using hdf5 module\n",
    "dat = '%sdat.hdf5' % dirs[0]\n",
    "lbl = '%slbl.hdf5' % dirs[0]\n",
    "\n",
    "dat = hdf5.load(dat)[0]\n",
    "lbl = hdf5.load(lbl)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about the HDF5 file format and the custom `hdf5` module as part of the `dl_core` library, see the following tutorial links (remote/local). Now, let us take a closer look at the data structure and view the underlying pixel information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect\n",
    "print(type(dat))\n",
    "print(dat.shape)\n",
    "print(lbl.shape)\n",
    "\n",
    "# --- View middle slice\n",
    "z = int(dat.shape[0] / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Client\n",
    "\n",
    "To efficiently load the data used in this tutorial, a special `Client` class has been prepared that handles many of the low-level tasks that need to be accounted for during algorithm training such as keeping track of training / validation splits and randomization between epochs. Importantly several medical imaging specific functionality has also been accounted for, including stratified sampling by disease entity and statistics for image normalization. For more information about the `Client` class and how to customize, see the following tutorial links (remote/local). \n",
    "\n",
    "For this tutorial, we leverage this class by creating a custom preprocessing method for this experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClient(Client):\n",
    "    \n",
    "    def preprocess(self, arrays, meta):\n",
    "        \"\"\"\n",
    "        Method to preprocess arrays\n",
    "        \n",
    "        :params\n",
    "        \n",
    "          (np.ndarray) arrays['dat']: input data\n",
    "          (np.ndarray) arrays['lbl']: input labels\n",
    "          (dict) meta : metadata information about current data\n",
    "        \n",
    "        \"\"\"\n",
    "        # --- Preprocess data\n",
    "        \n",
    "        # --- Preprocess labels\n",
    "        arrays['lbl'] = (arrays['lbl'] >= 1).astype('uint8')\n",
    "        \n",
    "        return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will instantiate a new `client` object, set a stratified sampling rate and prepare the first valildation fold. In our experiment, we will choose to stratify our data sampling such that an even 50-50% of loaded examples contain a positive or negative finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Instantiate the data client\n",
    "client = MyClient()\n",
    "\n",
    "# --- Set 50/50% sampling rate\n",
    "client.set_sampling_rate({\n",
    "    1: 0.5,\n",
    "    2: 0.5})\n",
    "\n",
    "# --- Validate on the first (of 5 total) folds of data\n",
    "client.prepare(fold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
