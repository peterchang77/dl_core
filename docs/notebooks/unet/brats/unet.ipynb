{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "The following lines of code will download several external Python libraries with code prepared for this tutorial. More information and additional tutorials may be found at the following GitHub repository: https://github.com/peterchang77/dl_train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O setenv.py https://raw.githubusercontent.com/peterchang77/dl_utils/master/setenv.py\n",
    "from setenv import prepare_env\n",
    "prepare_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will download and prepare data for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_train import datasets\n",
    "datasets.download(name='brats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import \n",
    "\n",
    "The following modules will be used in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Input, Model, layers, models, losses, optimizers\n",
    "from tensorflow import math\n",
    "\n",
    "from dl_utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data you have downloaded above contains preprocessed images and labels for this tutorial. To access the data, we will prepare Python generators (`gen_train` and `gen_valid`) using the custom `datasets` module. Specifically, we will create generators that:\n",
    "\n",
    "* yield a total of 16 training examples per batch\n",
    "* use the first fold (=0) for validation\n",
    "* sample equally from foreground (`fg`) and background (`bg`) cases at 50% frequency each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train, gen_valid = datasets.prepare(name='brats', configs={\n",
    "    'batch': {\n",
    "        'size': 16,\n",
    "        'fold': 0,\n",
    "        'sampling': {\n",
    "            'fg': 0.5,\n",
    "            'bg': 0.5\n",
    "}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned Python generators yield a tuple `(xs, ys)` that conform to the Tensorflow / Keras 2.0 API for training input(s) and output(s). Let us take a closer look here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield the next batch\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "# --- Inspect xs and ys dictionaries\n",
    "print(xs.keys())\n",
    "print(ys.keys())\n",
    "\n",
    "# --- Inspect the `t2` array\n",
    "print(xs['t2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let us now view the underlying voxel data using the `imshow()` method available in the custom `dl_utils.display` module. This useful function can be used to directly visualize any 2D slice of data (first argument), as well as overlay any mask if optionally provided (second argument). \n",
    "\n",
    "Example usage as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(xs['flair'], ys['lbl'], figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "In this exercise, we will create a custom variant of the standard contracting-expanding netowrk topology, popularly referred to as a U-Net architecture. We will define the algorithm completely here in the next several code cells using the functional API of Tensorflow/Keras. For a more general overview of basic Tensorflow/Keras usage, see the following tutorial links (remote/local). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Convolutional Block\n",
    "\n",
    "To help facilitate concise and readable code, we will create template Python lambda functions to succintly define convolutional blocks, defined as the following series of consecutive operations:\n",
    "\n",
    "* convolution (or convolutional-transpose)\n",
    "* batch normalization\n",
    "* activation function (ReLU, leaky ReLU, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define convolution parameters\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to define the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \"\"\"\n",
    "    Method to create simple U-Net architecture\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Define input\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # --- Define contracting layers\n",
    "    l1 = conv1(16, inputs)\n",
    "    l2 = conv1(32, conv2(32, l1))\n",
    "    l3 = conv1(48, conv2(48, l2))\n",
    "    l4 = conv1(64, conv2(64, l3))\n",
    "    l5 = conv1(80, conv2(80, l4))\n",
    "\n",
    "    # --- Define expanding layers\n",
    "    l6 = tran2(64, l5)\n",
    "    l7 = tran2(48, conv1(64, l6 + l4))\n",
    "    l8 = tran2(32, conv1(48, l7 + l3))\n",
    "    l9 = tran2(16, conv1(32, l8 + l2))\n",
    "\n",
    "    logits = layers.Conv3D(filters=2, **kwargs)(conv1(16, l1 + l9))\n",
    "\n",
    "    return Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model and show summary\n",
    "model = create_model(arrays['dat'].shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Model\n",
    "\n",
    "Next, we must compile the model with the requisite objects that define training dynamics (e.g. how the algorithm with learn). This will include classes that encapsulate the model `optimizer`, `loss` and `metrics` for evaluating algorithm performance. For more information about how these strategies are determined and defined, see the following tutorial links (remote/local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=2e-4)\n",
    "\n",
    "# --- Define loss\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Metric\n",
    "\n",
    "In addition the standard evaluation metric of `accuracy` (% of pixels or voxels that are predicted correctly), we will also keep track of a common metric to evaluate spatial overlap of masks: the Dice score. To do so, we need to create a custom metric function. For more information about creating custom metrics (and losses) in Tensorflow/Keras, see the following tutorial links (remote/local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_dice():\n",
    "\n",
    "    def dice(y_true, y_pred):\n",
    "\n",
    "        true = y_true == 1\n",
    "        pred = y_pred[..., 1] > y_pred[..., 0] \n",
    "\n",
    "        A = math.count_nonzero(true & pred) * 2\n",
    "        B = math.count_nonzero(true) + math.count_nonzero(pred)\n",
    "\n",
    "        return A / B\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile\n",
    "\n",
    "At last we are ready to compile the model. This is done simply with a call using the `model.compile()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimzer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy', metric_dice()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "One of the primary advantages to the Tensorflow/Keras API is that by following the above \"recipe\" to customize, instantiate and compile a `model` object, several very easy-to-use interfaces are available for algorithm training. In this tutorial, we will use data prepared from Python generators (`gen_train` and `gen_valid` as above) to train the model using the `model.fit_generator()` method. Usage is shown as follows using a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train the model\n",
    "model.fit_generator(\n",
    "    generator=gen_train,\n",
    "    steps_per_epoch=500,\n",
    "    epochs=4,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "How did we do? The validation performance metrics (accuracy, Dice score) give us a reasonable benchmark, but the most important thing to do at the end of the day is to visually check some examples for yourself. Let us pass some validation data manually into the model using the `model.predict()` method and see some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data and preproces\n",
    "arrays = client.get(shape=SHAPE, split='valid')\n",
    "\n",
    "# --- Run prediction\n",
    "pred = model.predict(np.expand_dims(arrays['dat'], axis=0))\n",
    "mask = np.argmax(pred[0], axis=-1)\n",
    "\n",
    "# --- Show prediction\n",
    "imshow(arrays['dat'][0, ..., 1], mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. Note that any custom losses and/or metrics will need to be provided via a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "model.save('./models/unet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "model = models.load_model('./models/unet.hdf5', custom_objects={'dice': metric_dice()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
