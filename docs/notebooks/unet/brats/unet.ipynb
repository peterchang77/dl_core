{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "In preparation for this tutorial we will need to set up the proper environment: \n",
    "\n",
    "* configure Google Colab\n",
    "* install custom libraries\n",
    "* download data\n",
    "* Python imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab\n",
    "\n",
    "If you are running this tutorial in Google Colab, the first important thing to do is switch to a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```\n",
    "\n",
    "Next we need to select and/or upgrade a few specific library versions. We will do this using the following Jupyter magic commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.0, upgrade pyyaml (only in Google Colab)\n",
    "%tensorflow_version 2.x\n",
    "%pip install -U pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom libraries\n",
    "\n",
    "This tutorial will use several custom, external Python libraries to facilitate low-level data management, data visualization and other useful tools optimized for machine learning and other data science projects in healthcare. More information and additional tutorials may be found at the following GitHub repositories: \n",
    "\n",
    "* https://github.com/peterchang77/dl_train\n",
    "* https://github.com/peterchang77/dl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install dl_utils and dl_train library\n",
    "!wget -O setenv.py https://raw.githubusercontent.com/peterchang77/dl_utils/master/setenv.py\n",
    "from setenv import prepare_env\n",
    "prepare_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "Next we will download and prepare data for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_train import datasets\n",
    "datasets.download(name='brats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imports \n",
    "\n",
    "The following modules will be used in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Input, Model, layers, models, losses, optimizers\n",
    "from tensorflow import math\n",
    "\n",
    "from dl_utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data you have downloaded above contains preprocessed images and labels for this tutorial. To access the data, we will prepare Python generators (`gen_train` and `gen_valid`) using the custom `datasets` module. In addition, a custom `client` object will be created that will facilitate interaction with data.\n",
    "\n",
    "The `datasets.prepare(...)` method accepts a `configs` variable that defines:\n",
    "\n",
    "* `size`: training batch size\n",
    "* `fold`: fold to use for validation\n",
    "* `sampling`: stratified sampling strategy\n",
    "\n",
    "In this tutorial, we will use the following settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare Python generators\n",
    "gen_train, gen_valid, client = datasets.prepare(name='brats', configs={\n",
    "    'batch': {\n",
    "        'size': 16,          # ==> Use a batch size of 16\n",
    "        'fold': 0,           # ==> Use the first fold (=0) for validation\n",
    "        'sampling': {        # ==> Use a 50/50% stratified sampling of foreground and background\n",
    "            'fg': 0.5,\n",
    "            'bg': 0.5}}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned Python generators yield a tuple `(xs, ys)` that conform to the Tensorflow / Keras 2.0 API for training input(s) and output(s). Let us take a closer look here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Yield the next batch\n",
    "xs, ys = next(gen_train)\n",
    "\n",
    "# --- Inspect xs and ys dictionaries\n",
    "print(xs.keys())\n",
    "print(ys.keys())\n",
    "\n",
    "# --- Inspect the `t2` array\n",
    "print(xs['t2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let us now view the underlying voxel data using the `imshow()` method available in the custom `dl_utils.display` module. This useful function can be used to directly visualize any 2D slice of data (first argument), as well as overlay any mask if optionally provided (second argument). \n",
    "\n",
    "Example usage as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(xs['flair'], ys['lbl'], figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow / Keras Input() tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training input(s) are passed into a Tensorflow / Keras model via specific `Input()` objects, defined via `tf.keras.Input(...)`. For each input, the corresponding tensor `shape` and `dtype` should be defined. A convenience function as part of the custom `client` class can be used to generate corresponding `Input()` objects for all the arrays in `xs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Input() objects\n",
    "inputs = client.get_inputs(Input)\n",
    "\n",
    "for key, i in inputs.items():\n",
    "    print('{}: {}'.format(key, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "In this exercise, we will create a custom variant of the standard contracting-expanding netowrk topology, popularly referred to as a U-Net architecture. We will define the algorithm completely here in the next several code cells using the functional API of Tensorflow/Keras. For a more general overview of basic Tensorflow/Keras usage, see the following tutorial links (remote/local). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Convolutional Block\n",
    "\n",
    "To help facilitate concise and readable code, we will create template Python lambda functions to succintly define convolutional blocks, defined as the following series of consecutive operations:\n",
    "\n",
    "* convolution (or convolutional-transpose)\n",
    "* batch normalization\n",
    "* activation function (ReLU, leaky ReLU, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define convolution parameters\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to define the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs):\n",
    "    \"\"\"\n",
    "    Method to create simple U-Net architecture\n",
    "\n",
    "    \"\"\"\n",
    "    # --- Concatenate modalities\n",
    "    combined = layers.concatenate([\n",
    "        inputs['t2'],\n",
    "        inputs['flair'],\n",
    "        inputs['pre'],\n",
    "        inputs['post']\n",
    "    ])\n",
    "\n",
    "    # --- Define contracting layers\n",
    "    l1 = conv1(16, combined)\n",
    "    l2 = conv1(32, conv2(32, l1))\n",
    "    l3 = conv1(48, conv2(48, l2))\n",
    "    l4 = conv1(64, conv2(64, l3))\n",
    "    l5 = conv1(80, conv2(80, l4))\n",
    "\n",
    "    # --- Define expanding layers\n",
    "    l6 = tran2(64, l5)\n",
    "    l7 = tran2(48, conv1(64, l6 + l4))\n",
    "    l8 = tran2(32, conv1(48, l7 + l3))\n",
    "    l9 = tran2(16, conv1(32, l8 + l2))\n",
    "\n",
    "    logits = {}\n",
    "    logits['lbl'] = layers.Conv3D(filters=2, name='lbl', **kwargs)(conv1(16, l1 + l9))\n",
    "\n",
    "    return Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model and show summary\n",
    "model = create_model(inputs)\n",
    "model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Model\n",
    "\n",
    "Next, we must compile the model with the requisite objects that define training dynamics (e.g. how the algorithm with learn). This will include classes that encapsulate the model `optimizer`, `loss` and `metrics` for evaluating algorithm performance. For more information about how these strategies are determined and defined, see the following tutorial links (remote/local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=2e-4)\n",
    "\n",
    "# --- Define loss\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Metric\n",
    "\n",
    "In addition the standard evaluation metric of `accuracy` (% of pixels or voxels that are predicted correctly), we will also keep track of a common metric to evaluate spatial overlap of masks: the Dice score. To do so, we need to create a custom metric function. For more information about creating custom metrics (and losses) in Tensorflow/Keras, see the following tutorial links (remote/local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsc(epsilon=1):\n",
    "\n",
    "    def dice(y_true, y_pred):\n",
    "\n",
    "        true = y_true[..., 0] == 1\n",
    "        pred = y_pred[..., 1] > y_pred[..., 0] \n",
    "\n",
    "        A = math.count_nonzero(true & pred) * 2\n",
    "        B = math.count_nonzero(true) + math.count_nonzero(pred) + epsilon\n",
    "\n",
    "        return A / B\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile\n",
    "\n",
    "At last we are ready to compile the model. This is done simply with a call using the `model.compile()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss={'lbl': loss},\n",
    "    metrics={'lbl': dsc()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "One of the primary advantages to the Tensorflow/Keras API is that by following the above \"recipe\" to customize, instantiate and compile a `model` object, several very easy-to-use interfaces are available for algorithm training. In this tutorial, we will use data prepared from Python generators (`gen_train` and `gen_valid` as above) to train the model using the `model.fit_generator()` method. Usage is shown as follows using a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train the model\n",
    "model.fit_generator(\n",
    "    generator=gen_train,\n",
    "    steps_per_epoch=500,\n",
    "    epochs=4,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "How did we do? The validation performance metrics (accuracy, Dice score) give us a reasonable benchmark, but the most important thing to do at the end of the day is to visually check some examples for yourself. Let us pass some validation data manually into the model using the `model.predict()` method and see some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data and preproces\n",
    "arrays = client.get(split='valid', cohort='fg')\n",
    "\n",
    "# --- Run prediction\n",
    "pred = model.predict({k: np.expand_dims(v, axis=0) for k, v in arrays['xs'].items()})\n",
    "mask = np.argmax(pred[0], axis=-1)\n",
    "\n",
    "# --- Show prediction\n",
    "imshow(arrays['xs']['flair'], mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. Note that any custom losses and/or metrics will need to be provided via a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "model.save('./models/unet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "model = models.load_model('./models/unet.hdf5', custom_objects={'dice': dsc()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
