{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial we will introduce the new Tensorflow 2.0 / Keras API, as well as basic concepts related with neural networks.\n",
    "\n",
    "**Tensorflow 2.0 API**\n",
    "\n",
    "* creating models: sequential and functional API\n",
    "* creating optimizers\n",
    "* creating loss functions\n",
    "* algorithm training\n",
    "\n",
    "**Multilayer Perceptron (MLPs)**\n",
    "\n",
    "* matrix multiplication\n",
    "* activation functions\n",
    "\n",
    "**Convolutional Neural Networks (CNNs)**\n",
    "\n",
    "* convolutional operations\n",
    "* spatial downsampling\n",
    "\n",
    "*Advanced Topics*\n",
    "\n",
    "* batch normalization\n",
    "* weight regularization\n",
    "* advanced activation functions\n",
    "* custom loss functions\n",
    "* custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0 API\n",
    "\n",
    "Tensorflow is a free and open-source software library developed by the Google Brain team for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is most popularly used for machine learning applications such as neural networks. In November 2019, the first stable release of the verson 2.0 library was made available, with significant changes including:\n",
    "\n",
    "* formal integration of the high-level Keras API for easy model building\n",
    "* `eager execution` of code, eliminating the need to manually compile an abstract syntax tree using a `session.run()` call\n",
    "* improved support for model deployment in production on any platform\n",
    "* improved support for distributed machine learning paradigms\n",
    "\n",
    "More information highlighting the key improvements can be found here: https://www.tensorflow.org/guide/effective_tf2\n",
    "\n",
    "## Import\n",
    "\n",
    "In this tutorial we will use the following Numpy and Tensorflow library components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Keras\n",
    "\n",
    "To develop a model using the Tensorflow/Keras API, we need to define two key objects: a Keras `model` and a Keras `layer`. After a `model` has been created with multiple `layers` the model needs to be *compiled* prior to algorithm *training*. In the following sections, we will introduce these key concepts then show how to instatiate and use these objects in Python. \n",
    "\n",
    "**NOTE**: We will be introducing *concepts* in these tutorial without any formal dataset for algorithm training and evalulation. See subsequent tutorials for more detailed information and guides for training specific neural network architectures on various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras models \n",
    "\n",
    "A Keras `model` is a high-level object that encapsulates and organizes one or multiple Keras `layers`. There are two main types of models available in Keras: the `Sequential` model, and the `Model` class used with the functional API.\n",
    "\n",
    "All Keras models have a number of methods and attributes in common:\n",
    "\n",
    "* `model.layers` is a flattened list of the layers comprising the model\n",
    "* `model.inputs` is the list of input tensors of the model\n",
    "* `model.outputs` is the list of output tensors of the model\n",
    "* `model.summary()` prints a summary representation of your model\n",
    "\n",
    "In addition there are a number of key methods used to pass data through the model during training and inference:\n",
    "\n",
    "* `model.fit()` is used to train a model with data\n",
    "* `model.evaluate()` is used to evaluate moel performance\n",
    "* `model.predict()` is used to pass new data to a trained network\n",
    "\n",
    "More information can be found here: https://keras.io/models/about-keras-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras layers\n",
    "\n",
    "A Keras `layer` is a `callable` Python object that represents functionality for a single layer in a neural network model. All Keras layers have a number of methods in common:\n",
    "\n",
    "* `layer.get_weights()` returns the weights of the layer as a list of Numpy arrays\n",
    "* `layer.set_weights(weights)` sets the weights of the layer from a list of Numpy arrays (with the same shapes as the output of get_weights)\n",
    "* `layer.get_config()` returns a dictionary containing the configuration of the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example of instantiating a new Keras layer object\n",
    "layer = layers.Dense(32)\n",
    "\n",
    "# --- Example of invoking a common layer method to get configurations\n",
    "print(type(layer))\n",
    "print(layer.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information can be found here: https://keras.io/layers/about-keras-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "As described above, there are two primary ways to create a model using Tensorflow/Keras: the `Sequential` model and the functional API using the `Model` class. For maxmimum flexibility, we will use the functional API throughout all tutorials, however we will also demonstrate the `Sequential` model here for completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model\n",
    "\n",
    "The `Sequential` model allows you to define simple architectures layer-by-layer in a *sequential* manner. However this approach is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs. Nonetheless for a conventional feed-forward neural network, this approach may be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Option #1: add layer objects in list\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, input_shape=(784,)),\n",
    "    layers.ReLU(),\n",
    "    layers.Dense(10),\n",
    "    layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Option #2: add layer objects using the add() method\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print summary of model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API\n",
    "\n",
    "The functional API allows for a broader flexibility to model definition. To use, simply define an arbitrary graph structure by passing layers into one another until the entire network has been templated. Then, select one or multiple input(s) and one or multiple output(s) to pass as arguments into the `Model` class constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define graph by passing layers into one another\n",
    "inputs = Input(shape=(784,))\n",
    "x = layers.Dense(32)(inputs)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dense(10)(x)\n",
    "x = layers.Softmax()(x)\n",
    "\n",
    "# --- Define model by passing input(s) and output(s)\n",
    "model = Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print summary of model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been defined, let us prepare our model for training. To do so we will need to formally **compile** the graph and define the training process using several key components (each represented by Keras Python objects):\n",
    "\n",
    "* loss function\n",
    "* optimizer\n",
    "* metric(s) (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a loss object\n",
    "\n",
    "Keras has a number of loss functions encapsulated by Python classes in the `tf.losses.*` module. The most commonly used include:\n",
    "\n",
    "* categorical cross entopy (classification tasks)\n",
    "* mean absolute or squared errors (regressions tasks)\n",
    "* Huber loss (many box algorithms)\n",
    "\n",
    "**IMPORTANT**: if you are training a classification task and your last model layer *does not* include an activation function (e.g. it represents raw logit scores) you must use the `from_logits=True` flag when defining you loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define a MAE loss\n",
    "loss = losses.MeanAbsoluteError()\n",
    "\n",
    "# --- Define a categorical cross-entropy loss\n",
    "loss = losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an optimizer object\n",
    "\n",
    "Keras has a number of optimizer functions encapsulated by Python classes in the `tf.optimizers.*` module. The most commonly used include:\n",
    "\n",
    "* stochastic gradient descent\n",
    "* SGD + momentum\n",
    "* Adam (recommended by default)\n",
    "\n",
    "To instantiate a new optimizer object, simply pass the learning rate into the class constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define an SGD optimizer\n",
    "optimizer = optimizers.SGD(learning_rate=2e-4)\n",
    "\n",
    "# --- Define an Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a metric\n",
    "\n",
    "While losses are used by a neural network to guide optimization of model parameters, metrics are used by a human to gauage model performance in a more easily interpretable way. The most common metric for classification tasks is overall model `accuracy` (%). Other custom metrics can be defined as shown in advanced sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling\n",
    "\n",
    "Once the model `optimizer`, `loss` and `metric` have been defined, simply pass these objects into the `model.compile()` method to prepare for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now compiled and ready for training! See subsequent tutorials for more detaisl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. Note that any custom losses and/or metrics will need to be provided via a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Serialize a model\n",
    "model.save('./intro.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load a serialized model\n",
    "del model\n",
    "model = models.load_model('./intro.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Delete saved model\n",
    "import os\n",
    "os.remove('./intro.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
